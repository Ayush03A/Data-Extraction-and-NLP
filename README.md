
# ğŸ§  Textual Analysis & Web Scraping Project with Python

This project automates the process of **scraping article content from URLs**, cleaning and processing text, and performing **natural language processing (NLP)** to analyze the **polarity, subjectivity, and sentiment** of the content.

It uses tools such as **BeautifulSoup** for web scraping, **NLTK** for natural language processing, and **pandas** for data handling and Excel export.

> ğŸ“Œ [Run on Google Colab](https://colab.research.google.com/drive/1PFolDMuYbIphIp-QxVX3oZ-huZG-6Za8)

---

## ğŸ“Œ Project Overview

This Python-based solution reads a CSV of article URLs, scrapes their content, cleans the text, and performs a comprehensive textual analysis. The final results â€” including various sentiment scores and counts â€” are saved in an Excel file for reporting and further data analysis.

---

## ğŸ“š Features & Approach

### ğŸ” Web Scraping

- âœ… Scrapes article **titles** and **text bodies** from given URLs
- âœ… Uses `requests` and `BeautifulSoup` for HTML parsing
- âœ… Extracts clean, structured content ready for NLP

### ğŸ§¼ Text Cleaning

- âœ… Removes **stop words** from text (custom stop words list supported)
- âœ… Prepares text for tokenization and analysis

### ğŸ§  Textual Analysis

- âœ… **Word tokenization**
- âœ… **Frequency counts**
- âœ… **Polarity score** (positive vs negative word density)
- âœ… **Subjectivity score**
- âœ… Counts of:
  - Positive words
  - Negative words
  - Complex words
  - Average sentence length
  - Fog Index
  - Word Count
  - Sentence Count

### ğŸ“ File Input & Output

- ğŸ§¾ Takes a CSV input file with article URLs
- ğŸ“‚ Stores scraped articles as individual `.txt` files
- ğŸ“Š Outputs results into a formatted **Excel sheet**

---

## ğŸ§  Project Workflow

```plaintext
ğŸ“¥ Input CSV (URLs)
      â†“
ğŸ” Scrape article titles & text (requests + BeautifulSoup)
      â†“
ğŸ§½ Clean & preprocess text (remove stopwords, tokenize)
      â†“
ğŸ“Š Perform NLP analysis (NLTK)
      â†“
ğŸ“ Save results as text + Excel
```

---

## ğŸ§° Dependencies & Setup

Ensure you have the following installed in your environment:

### âœ… Dependencies

- Python >= 3.6
- [pandas](https://pandas.pydata.org/)
- [requests](https://pypi.org/project/requests/)
- [BeautifulSoup4](https://pypi.org/project/beautifulsoup4/)
- [nltk](https://www.nltk.org/)

## ğŸ’» Installation

Install all required libraries using `pip`:

```bash
pip install pandas requests beautifulsoup4 nltk
```

---

## ğŸ› ï¸ How to Run the Script

### ğŸ–¥ï¸ On Local System

1. Make sure the following files are present in your working directory:
   - `input.csv` â€” contains the list of article URLs
   - `positive-words.txt` â€” list of positive words
   - `negative-words.txt` â€” list of negative words
   - `stopwords.txt` â€” list of stop words

2. Clone or download the repository:

```bash
git clone https://github.com/your-username/your-repo-name.git
cd your-repo-name
```

3. Run the Python script:

```bash
python script_name.py
```

4. Output files will be generated:
   - Scraped `.txt` files in the designated folder
   - Final analysis in `output.xlsx`

---

## ğŸ“Š Sample Output Columns

| URL | Title | Polarity Score | Subjectivity Score | Average Sentence Length | Fog Index | Word Count | Complex Word Count |
|-----|-------|----------------|--------------------|--------------------------|-----------|-------------|---------------------|
| ... | ...   | 0.25           | 0.67               | 12.3                     | 8.5       | 450         | 68                  |

---

## ğŸ§ª Code Structure

```plaintext
ğŸ“ Project Root
â”œâ”€â”€ script_name.py              # Main Python script
â”œâ”€â”€ input.csv                   # Input URLs
â”œâ”€â”€ stopwords.txt               # Stop words list
â”œâ”€â”€ positive-words.txt          # Positive sentiment words
â”œâ”€â”€ negative-words.txt          # Negative sentiment words
â”œâ”€â”€ output/                     # Folder for scraped .txt articles
â””â”€â”€ output.xlsx                 # Final analysis report
```

---

## ğŸ“ˆ Future Enhancements

- ğŸ”„ Add support for additional sentiment lexicons (e.g., VADER, TextBlob)
- ğŸŒ Use newspaper3k or langchain for richer article parsing
- ğŸ“Š Generate visual dashboards (matplotlib/Plotly)
- â˜ï¸ Automate in the cloud using Airflow or Lambda

---

## ğŸ§¾ License

This project is licensed under the **MIT License**.  
Feel free to modify and use it for your own educational or commercial purposes.

---

## ğŸ‘¤ Author

- **Ayush Anand**
- ğŸ“§ [0310ayushanand@gmail.com](mailto:0310ayushanand@gmail.com)
- ğŸ”— [GitHub: Ayush03A](https://github.com/Ayush03A)

---

â­ï¸ *Found this helpful? Give it a star and share it with your peers!*
